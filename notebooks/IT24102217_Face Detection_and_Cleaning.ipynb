{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc75c351-5c65-4084-9855-87d7ef274720",
   "metadata": {},
   "source": [
    "# 02. IT24102217 – Face Detection and Cleaning\n",
    "###### Technique: Image loading, grayscale conversion, Haar Cascade detection, cropping, resizing.\n",
    "###### Problem: Dataset contained unreadable images and photos without detectable faces, causing noise.\n",
    "###### Solution:\n",
    "\n",
    "Skip unreadable images.\n",
    "\n",
    "Convert images to grayscale.\n",
    "\n",
    "Detect faces using Haar Cascade.\n",
    "\n",
    "Crop and resize detected face regions (50×50).\n",
    "\n",
    "Append only valid faces to dataset.\n",
    "\n",
    "Flatten images into vectors (2500 features).\n",
    "\n",
    "###### Why Needed: Guarantees clean, standardized face-only data, improving reliability of training and reducing errors.\n",
    "###### Visualization: Bar chart showing valid faces collected vs. skipped images (load error / no face)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcaf6d3-6100-4dd3-99b7-fee586a71036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "data = []\n",
    "target = []\n",
    "skipped_load_error = 0\n",
    "skipped_no_face = 0\n",
    "processed_images_count = 0 \n",
    "\n",
    "for label in labels:\n",
    "    imgs_path = os.path.join(data_path, label) #get the each catagari one by one\n",
    "    img_names = os.listdir(imgs_path)\n",
    "\n",
    "    for img_name in img_names:   # get the each image one by one\n",
    "        img_path = os.path.join(imgs_path, img_name)\n",
    "        processed_images_count += 1  # Increment the count for each image processed\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None: # idintify loading error data\n",
    "            print(f\"Warning: Could not load image {img_path}\")\n",
    "            skipped_load_error += 1\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to the image gray scale\n",
    "        faces = face_classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) # idintify face \n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(f\"No faces detected in {img_name}\") #idintify no face image\n",
    "            skipped_no_face += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            for (x, y, w, h) in faces:\n",
    "                cropped_face = gray[y:y+h, x:x+w]\n",
    "                cropped_face = cv2.resize(cropped_face, (50, 50)) # crope the face\n",
    "                data.append(cropped_face)\n",
    "                target.append(category_dict[label])\n",
    "\n",
    "                # Show first detected face (optional)\n",
    "                plt.imshow(cropped_face, cmap=\"gray\")\n",
    "                plt.title(f\"Detected Face - {label}\")\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "                break  # Show only one face per image for preview\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_name}: {e}\")\n",
    "            pass\n",
    "\n",
    "print(f\"Finished processing. Collected {len(data)} faces.\")\n",
    "print(f\"Images skipped due to loading errors: {skipped_load_error}\")\n",
    "print(f\"Images skipped due to no face detected: {skipped_no_face}\")\n",
    "print(f\"Total images attempted: {processed_images_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f4a66-d305-4d6f-8d50-727a83c15442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data', 'skipped_load_error', and 'skipped_no_face' are available from the previous processing step.\n",
    "\n",
    "valid_faces_count = len(data)\n",
    "# We can consider images skipped due to no face or loading errors as \"invalid\" image sources for face data\n",
    "invalid_images_count = skipped_load_error + skipped_no_face\n",
    "\n",
    "# Prepare data for plotting\n",
    "categories = ['Valid Faces Collected', 'Images Skipped (No Face/Load Error)']\n",
    "counts = [valid_faces_count, invalid_images_count]\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(categories, counts, color=['green', 'red'])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Valid Faces vs. Skipped Images\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a679ea-2b26-4c82-b9af-7c3678b75b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(data)\n",
    "data=data.reshape(data.shape[0],data.shape[1]*data.shape[2])\n",
    "target=np.array(target)\n",
    "print(\"Flattened data shape:\", data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
